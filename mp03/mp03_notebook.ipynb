{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS440/ECE448 Spring 2023\n",
    "# MP03: K-nearest Neighbors Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you need to do is to download this file: <a href=\"mp03.zip\">mp03.zip</a>.  It has the following content:\n",
    "\n",
    "* `submitted.py`: Your homework. Edit, and then submit to <a href=\"https://www.gradescope.com/courses/486387\">Gradescope</a>.\n",
    "* `mp03_notebook.ipynb`: This is a <a href=\"https://anaconda.org/anaconda/jupyter\">Jupyter</a> notebook to help you debug.  You can completely ignore it if you want, although you might find that it gives you useful instructions.\n",
    "* `grade.py`: Once your homework seems to be working, you can test it by typing `python grade.py`, which will run the tests in `tests/tests_visible.py`.\n",
    "* `tests/test_visible.py`: This file contains about half of the <a href=\"https://docs.python.org/3/library/unittest.html\">unit tests</a> that Gradescope will run in order to grade your homework.  If you can get a perfect score on these tests, then you should also get a perfect score on the additional hidden tests that Gradescope uses.\n",
    "* `solution.json`: This file contains the solutions for the visible test cases, in <a href=\"https://docs.python.org/3/library/json.html\">JSON</a> format.  If the instructions are confusing you, please look at this file, to see if it can help to clear up your confusion.\n",
    "* `data`: This directory contains the data.\n",
    "* `reader.py`: This is an auxiliary program that you can use to read the data.\n",
    "\n",
    "Please note that there is no extra packages that you should be using except for NumPy. Specifically, you are not allowed to use scikit-learn for this mp(**using the built-in KNN classifier would result in an automatic 0!**)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file (`mp03_notebook.ipynb`) will walk you through the whole MP, giving you instructions and debugging tips as you go.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. <a href=\"#section1\">Reading the data</a>\n",
    "1. <a href=\"#section2\">Using Numpy</a>\n",
    "1. <a href=\"#section3\">K-nearest Neighbors</a>\n",
    "1. <a href=\"#section4\">Prediction and Evaluation</a>\n",
    "1. <a href=\"#grade\">Grade Your Homework</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## Reading the data\n",
    "The dataset consists of 10000 32x32 colored images total. We have split this data set for you into 2500 development examples and 7500 training examples. The images have their RGB values scaled to range 0-1. This is a subset of the CIFAR-10 dataset, provided by Alex Krizhevsky.\n",
    "\n",
    "The reader will supply the set of test images as one giant numpy array. The development data is in the same format. So your code must read the dimensions from the input numpy array.\n",
    "\n",
    "In the dataset, each image is 32x32 and has three (RGB) color channels, yielding 32*32*3 = 3072 features. However, be aware that synthetic tests in the autograder may have different dimensions. So do not hardcode the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module reader:\n",
      "\n",
      "NAME\n",
      "    reader - This file is responsible for providing functions for reading the files\n",
      "\n",
      "FUNCTIONS\n",
      "    listdir(path=None)\n",
      "        Return a list containing the names of the files in the directory.\n",
      "        \n",
      "        path can be specified as either str, bytes, or a path-like object.  If path is bytes,\n",
      "          the filenames returned will also be bytes; in all other circumstances\n",
      "          the filenames returned will be str.\n",
      "        If path is None, uses the path='.'.\n",
      "        On some platforms, path may also be specified as an open file descriptor;\\\n",
      "          the file descriptor must refer to a directory.\n",
      "          If this functionality is unavailable, using it raises NotImplementedError.\n",
      "        \n",
      "        The list is in arbitrary order.  It does not include the special\n",
      "        entries '.' and '..' even if they are present in the directory.\n",
      "    \n",
      "    load_dataset(filename, extra=False, sanity_check=False)\n",
      "    \n",
      "    load_fulldata(filename)\n",
      "    \n",
      "    unpickle(file)\n",
      "\n",
      "FILE\n",
      "    c:\\users\\wonde\\ece448labs\\spring23\\mp03\\src\\reader.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import reader\n",
    "help(reader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the training and development. Print the first 10 samples to see how the training set looks like. The dev set looks similar to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of Training Images\n",
      "[[0.13333333 0.15294118 0.15686275 ... 0.12941176 0.19215686 0.23529412]\n",
      " [0.38823529 0.38431373 0.38431373 ... 0.57647059 0.58039216 0.56862745]\n",
      " [0.79607843 0.79215686 0.79607843 ... 0.77647059 0.77647059 0.76862745]\n",
      " ...\n",
      " [0.36078431 0.38431373 0.40784314 ... 0.60784314 0.67843137 0.65098039]\n",
      " [0.90980392 0.67058824 0.39215686 ... 0.05490196 0.16470588 0.2627451 ]\n",
      " [1.         1.         1.         ... 0.80392157 0.83137255 0.82745098]]\n",
      "First 10 of Training Labels\n",
      "[ True False False False False  True False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, dev_images,dev_labels = reader.load_dataset('mp3_data', extra=True)\n",
    "print(\"First 10 of Training Images\")\n",
    "print(train_images[:10])\n",
    "print(\"First 10 of Training Labels\")\n",
    "print(train_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Using numpy\n",
    "For this MP (unlike some previous MPs), it is much easier to write fast code by using numpy operations. Your data is provided as a numpy array. Use numpy operations as much as possible, until right at the end when you choose a label for each image and produce the output list of labels.\n",
    "\n",
    "NumPy Tips:\n",
    "\n",
    "* Running computations on arrays tend to be faster when run using NumPy arrays. If you are having issues with timing out, then consider using a NumPy implementation\n",
    "* Linear algebra operators (dot product, vector norm, matrix multiplication) are immensely simplified when using NumPy. Consider looking up methods to perform some of these operations if they are needed in your solution.\n",
    "* <a href=\"https://numpy.org/doc/stable/user/basics.broadcasting.html\">NumPy Broadcasting</a> may make your life easier for this assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## K-nearest neighbors\n",
    "implement the K-Nearest Neighbor algorithm. See the textbook, lecture notes, and/or <a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\">Wikipedia</a> page for details. Your implementation should use Euclidean distance. **To break ties, use the negative label (no animal class).** You must implement this algorithm on your own with only standard libraries and NumPy.\n",
    "\n",
    "Note: To prevent memory errors due to the autograder's limitations, your algorithm should iterate through the list of test images rather than (say) creating a vector containing all the test images.\n",
    "\n",
    "Our autograder tests will pass in various values for the parameter k. You may not reset k inside your classifier function. For your own understanding, you should experiment with different values of k to see how this affects the accuracy. Also try to understand how this algorithm compares to a perceptron, in accuracy but also efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we'll load the file `submitted.py`.\n",
    "\n",
    "The file `submitted.py` is the only part of your work that the autograder will see. The only purpose of this notebook is to help you debug `submitted.py`.  Once you have revised `submitted.py` enough to make this notebook work, then you should go to the command line, and type `python grade.py`.  Once that command returns without errors, then  you can go ahead and submit your file `submitted.py` to the autograder.  You can submit to the autograder as often as you want, but it will save you trouble if you debug as much as you can on your local machine, before you submit to the autograder.\n",
    "\n",
    "We will use `importlib` in order to reload your `submitted.py` over and over again.  That way, every time you make a modification in `submitted.py`, you can just re-run  the corresponding block of this notebook, and it will reload `submitted.py` with your modified code.  \n",
    "\n",
    "Since the file is called `submitted.py`, python considers it to contain a module called `submitted`.  As shown, you can read the module's docstring by printing `submitted.__doc__`.  You can also type `help(submitted)` to get a lot of information about the module, including its docstring, a list of all the functions it defines, and all of their docstrings.  For  more about docstrings, see, for example, https://www.python.org/dev/peps/pep-0257/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the module you'll submit to the autograder.\n",
      "\n",
      "There are several function definitions, here, that raise RuntimeErrors.  You should replace\n",
      "each \"raise RuntimeError\" line with a line that performs the function specified in the\n",
      "function's docstring.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import submitted\n",
    "import importlib\n",
    "importlib.reload(submitted)\n",
    "print(submitted.__doc__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for you to open `submitted.py`, and start editing it.  You can open it in another Jupyter window by choosing \"Open from Path\" from the \"File\" menu, and then typing `submitted.py`.  Alternatively, you can use any text editor.\n",
    "\n",
    "Once you have it open, try editing the function `k_nearest_neighbors` so that its functionality matches its docstring.  Your function `k_nearest_neighbors` will take input including one image, train images, train_labels and the number of neighbors used (k). It should return k nearest neighbors of image and k nearest labels.\n",
    "Here is what it's docstring says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function k_nearest_neighbors in module submitted:\n",
      "\n",
      "k_nearest_neighbors(image, train_images, train_labels, k)\n",
      "    Parameters:\n",
      "    image - one image\n",
      "    train_images - a list of N images\n",
      "    train_labels - a list of N labels corresponding to the N images\n",
      "    k - the number of neighbors to return\n",
      "    \n",
      "    Output:\n",
      "    neighbors - a list of k images, the k nearest neighbors of image\n",
      "    labels - a list of k labels corresponding to the k images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(submitted.k_nearest_neighbors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit `k_nearest_neighbors` so that it does the task specified in its docstring. Note that you are free to change k value multiple times to see if the results change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top k neighbors\n",
      "[[0.13333333 0.15294118 0.15686275 ... 0.12941176 0.19215686 0.23529412]\n",
      " [0.21960784 0.21568627 0.22745098 ... 0.25098039 0.28627451 0.29803922]]\n",
      "\n",
      "Top k labels corresponding to k images\n",
      "[ True  True]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "neighbors, labels = submitted.k_nearest_neighbors(train_images[0], train_images, train_labels, k=2)\n",
    "print(\"Top k neighbors\")\n",
    "print(neighbors)\n",
    "print(\"\\nTop k labels corresponding to k images\")\n",
    "print(labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## Prediction and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you get your knn function working, you can start to predict with its output(`classify_devset`) and evaluate based on your output(`confusion_matrix`). \n",
    "Now, edit the functions `classify_devset` and `confusion_matrix` to finish the task as described in docstring.  The results you should get are shown below, and are also available to you in the file `solutions.json`. \n",
    "Let's read the docstring of `classify_devset` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function classify_devset in module submitted:\n",
      "\n",
      "classify_devset(dev_images, train_images, train_labels, k)\n",
      "    Parameters:\n",
      "    dev_images (list) -M images\n",
      "    train_images (list) -N images\n",
      "    train_labels (list) -N labels corresponding to the N images\n",
      "    k (int) - the number of neighbors to use for each dev image\n",
      "    \n",
      "    Output:\n",
      "    hypotheses (list) -one majority-vote labels for each of the M dev images\n",
      "    scores (list) -one majority-vote scores for each of the M dev images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(submitted.classify_devset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `classify_devset` function take development set images, training set images and labels, and number of neighbors as input. You are expected to used `k_nearest_neighbors` implemented from previous step and predict a list of labels(Hypotheses) corresponding to development set images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypotheses\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "y_hats,scores = submitted.classify_devset(dev_images, train_images, train_labels, k=2)\n",
    "print(\"Hypotheses\")\n",
    "print(y_hats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the docstring of `confusion_matrix`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confusion_matrix in module submitted:\n",
      "\n",
      "confusion_matrix(hypotheses, references)\n",
      "    Parameters:\n",
      "    hypotheses (list) - a list of M labels output by the classifier\n",
      "    references (list) - a list of the M correct labels\n",
      "    \n",
      "    Output:\n",
      "    confusions (list of lists, or 2d array) - confusions[m][n] is \n",
      "    the number of times reference class m was classified as\n",
      "    hypothesis class n.\n",
      "    accuracy (float) - the computed accuracy\n",
      "    f1(float) - the computed f1 score from the matrix\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(submitted.confusion_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking y_hat(the predicted labels) from previous step and development labels(the ground truth) as input, you are expected to compute a confusion matrix, accuracy and f1. Where\n",
    "confusion matrix is a 2*2 array in this format: \n",
    "|             | Predicted 0        | Predicted 1         |    \n",
    "| ----------- | ------------------ | ------------------- |\n",
    "| Actual 0    | True Negative(TN)  | False Positive(FP)  |\n",
    "| Actual 0    | False Negative(FN) | True Positive(TP)   |\n",
    "\n",
    "Accuracy and F1 score are defined as follows:\n",
    "$$Precision= \\frac{TP} {TP+FP}$$\n",
    "$$Recall= \\frac{TP} {TP+FN}$$\n",
    "$$Accuracy= \\frac{TP+TN} {TP+TN+FP+FN}$$\n",
    "$$F_1= \\frac{2} {\\frac{1}{Recall} * \\frac{1}{Precision}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed confusion matrix:\n",
      "[[ 73  31]\n",
      " [ 34 112]]\n",
      "The accuracy is: 0.74\n",
      "The F1 score is: 0.7750865051903114\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "confusions, accuracy, f1 = submitted.confusion_matrix(y_hats, dev_labels)\n",
    "print(\"Computed confusion matrix:\")\n",
    "print(confusions)\n",
    "print(\"The accuracy is:\", accuracy)\n",
    "print(\"The F1 score is:\", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grade'></a>\n",
    "## Grade your homework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've reached this point, and all of the above sections work, then you're ready to try grading your homework!  Before you submit it to Gradescope, try grading it on your own machine.  This will run some visible test cases (which you can read in `tests/test_visible.py`), and compare the results to the solutions (which you can read in `solution.json`).\n",
    "\n",
    "The exclamation point (!) tells python to run the following as a shell command.  Obviously you don't need to run the code this way -- this usage is here just to remind you that you can also, if you wish, run this command in a terminal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 4.545s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python grade.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you got any 'E' marks, it means that your code generated some runtime errors, and you need to debug those.\n",
    "\n",
    "If you got any 'F' marks, it means that your code ran without errors, but that it generated results that are different from the solutions in `solutions.json`.  Try debugging those differences.\n",
    "\n",
    "If neither of those things happened, and your result was a series of dots, then your code works perfectly.  \n",
    "\n",
    "If you're not sure, you can try running grade.py with the -j option.  This will produce a JSON results file, in which the best score you can get is 50."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should try uploading `submitted.py` to <a href=\"https://www.gradescope.com/courses/486387\">Gradescope</a>.  \n",
    "\n",
    "Gradescope will run the same visible tests that you just ran on your own machine, plus some additional hidden tests.  It's possible that your code passes all the visible tests, but fails the hidden tests.  If that happens, then it probably means that you hard-coded a number into your function definition, instead of using the input parameter that you were supposed to use.  Debug by running your function with a variety of different input parameters, and see if you can get it to respond correctly in all cases.\n",
    "\n",
    "Once your code works perfectly on Gradescope, with no errors, then you are done with the MP.  Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grade'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "275f9977005cbeacf5a20d3240c1e9f45a6961eeea911ae001ba16acd14deec2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
